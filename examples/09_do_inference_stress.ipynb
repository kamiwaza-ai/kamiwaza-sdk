{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Stress Test with Kamiwaza SDK\n",
    "\n",
    "This notebook demonstrates how to perform a multi-threaded stress test on deployed models using the Kamiwaza SDK.\n",
    "\n",
    "The test sends multiple concurrent requests to stress test the inference endpoint and measure performance metrics like:\n",
    "- Response times\n",
    "- Token throughput (tokens/second)\n",
    "- Average token usage per request\n",
    "\n",
    "This is especially important for engines like vLLM that benefit from continuous batching - you need concurrent requests to see real performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Kamiwaza Client\n",
    "\n",
    "First, we connect to the Kamiwaza server and list all active deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 active deployment(s):\n",
      "  1. Qwen3-8B-GGUF (Status: DEPLOYED, Endpoint: http://localhost:61100/v1)\n",
      "\n",
      "Using deployment: Qwen3-8B-GGUF\n"
     ]
    }
   ],
   "source": [
    "from kamiwaza_sdk import kamiwaza_sdk as kz\n",
    "\n",
    "# Initialize the client\n",
    "client = kz(\"http://localhost:7777/api/\")\n",
    "\n",
    "# List all active deployments\n",
    "deployments = client.serving.list_active_deployments()\n",
    "\n",
    "if not deployments:\n",
    "    print(\"No active deployments found. Please deploy a model first.\")\n",
    "else:\n",
    "    print(f\"Found {len(deployments)} active deployment(s):\")\n",
    "    for i, dep in enumerate(deployments):\n",
    "        print(f\"  {i+1}. {dep.m_name} (Status: {dep.status}, Endpoint: {dep.endpoint})\")\n",
    "    \n",
    "    # Select the first deployment for testing\n",
    "    selected_deployment = deployments[0]\n",
    "    print(f\"\\nUsing deployment: {selected_deployment.m_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Test Parameters\n",
    "\n",
    "Set the number of prompts to run and prepare the test configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a gentle test, set this to a positive number (e.g., 5)\n",
    "# For full stress test, set to -1 to run all prompts\n",
    "PROMPTS_TO_RUN = 5  # Start with 5 for testing\n",
    "# PROMPTS_TO_RUN = -1  # Uncomment for full stress test\n",
    "\n",
    "# Number of concurrent workers\n",
    "MAX_WORKERS = 128  # Adjust based on your system capabilities\n",
    "\n",
    "# Request timeout in seconds\n",
    "REQUEST_TIMEOUT = 600  # 10 minutes\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "\n",
    "# Reduce noise from all loggers\n",
    "for logger_name in logging.root.manager.loggerDict:\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Test Prompts\n",
    "\n",
    "We'll use a variety of coding-related prompts to test the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total prompts available: 59\n",
      "Will run: 5 prompts\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Core test prompts\n",
    "core_prompts = [\n",
    "    \"write me code in python to efficiently print prime numbers 0..1b\",\n",
    "    \"write me a fastapi server that handles notes and can get/put them\",\n",
    "    \"write me code that demonstrates a simple version of doing a 3-param linear regression model for home prices with price, sqft, rooms to predict prices in that market given sqft/rooms, training set in /tmp/trainingdata.json named 'price', 'sqft', 'rooms' as columns, count the number of rows in the code and split 90/10 training/testing\",\n",
    "    \"write me a fastapi server that has endpoints for playing tic tac toe\",\n",
    "    \"write me a fastapi server that has endpoints for playing chess; ensure all moves are valid; use chess notation for moves\",\n",
    "    \"write me a list of the 50 most influential ai/compsci pioneers, 1 per line, numbered 1..50, with 10-12 words on why they belong on the list; you must not repeat any name\",\n",
    "    \"write me an example of factoring an exceedingly large prime with a quantum computer\",\n",
    "    \"show me three examples of messy python code that can be improved to be more idiomatic/pythonic with a comprehension\",\n",
    "    \"come up with a sqlalchemy schema for a D&D 5e character\"\n",
    "]\n",
    "\n",
    "# Extended test prompts\n",
    "extended_prompts = [\n",
    "    \"Python script that scrapes weather data from a website and saves it in a CSV file\",\n",
    "    \"create a Django app for a blog where users can post, edit, and delete their blogs\",\n",
    "    \"write a Python function to convert a given text into Morse Code\",\n",
    "    \"design a Python program that uses machine learning to predict stock market prices\",\n",
    "    \"develop a command-line tool in Python for renaming files in bulk according to a specified pattern\",\n",
    "    \"write a Python script to automate login to a website and download a specific file\",\n",
    "    \"create a Flask API for a todo list application with CRUD operations\",\n",
    "    \"write a Python script that uses OpenCV for facial recognition\",\n",
    "    \"develop a Python-based text editor with basic functionalities like open, edit, and save files\",\n",
    "    \"create a Python script for a basic chatbot that can answer FAQs\",\n",
    "    \"write a Python program that solves Sudoku puzzles\",\n",
    "    \"develop a web scraper in Python to collect data from multiple pages of a website\",\n",
    "    \"write a Python script to monitor and log CPU and memory usage over time\",\n",
    "    \"create a Python program that encrypts and decrypts text using a custom cipher\",\n",
    "    \"write a Python script that visualizes data from a CSV file using Matplotlib\",\n",
    "    \"develop a Python-based system for tracking and managing inventory\",\n",
    "    \"create a Python program to analyze and plot cryptocurrency trends\",\n",
    "    \"write a Python script that automates sending emails with attachments\",\n",
    "    \"develop a Python application that converts speech to text\",\n",
    "    \"write a Python-based calculator for complex mathematical expressions\",\n",
    "    \"create a Python script to compare two text files and highlight differences\",\n",
    "    \"develop a Python program that uses natural language processing to summarize text\",\n",
    "    \"write a Python script for a password generator that creates strong, unique passwords\",\n",
    "    \"create a Python-based tool for organizing and renaming photos based on date and location\",\n",
    "    \"develop a Python script that tracks prices of products on e-commerce websites and sends alerts\",\n",
    "    \"write a Python program for a simple expense tracker\",\n",
    "    \"create a Python script to automate data entry into a web form\",\n",
    "    \"develop a Python tool for visualizing geographic data on a map\",\n",
    "    \"write a Python script to analyze and predict weather patterns\",\n",
    "    \"create a Python-based server monitoring tool that sends alerts for downtime\"\n",
    "]\n",
    "\n",
    "# Additional challenging prompts\n",
    "additional_prompts = [\n",
    "    \"write a Python script to organize and analyze personal finance data from bank statements\",\n",
    "    \"create a Python-based GUI application for a digital address book\",\n",
    "    \"develop a Python script that automates the creation of PowerPoint presentations from a text outline\",\n",
    "    \"write a Python program to generate music playlists based on mood analysis\",\n",
    "    \"create a Python script for a basic file encryption and decryption tool\",\n",
    "    \"develop a Python-based web application for real-time sports scores and statistics\",\n",
    "    \"write a Python program to automate the process of image tagging using AI\",\n",
    "    \"create a Python script for real-time chat translation for multiple languages\",\n",
    "    \"develop a Python tool for tracking and managing personal health data\",\n",
    "    \"write a Python-based system for managing library books and members\",\n",
    "    \"create a Python script to convert handwriting to text using machine learning\",\n",
    "    \"develop a Python program for a restaurant reservation system\",\n",
    "    \"write a Python script for a tool that optimizes travel routes and schedules\",\n",
    "    \"create a Python-based application for tracking and managing event tickets\",\n",
    "    \"develop a Python script for a workout planner and tracker\",\n",
    "    \"write a Python program for a real-time collaborative whiteboard\",\n",
    "    \"create a Python script to generate and analyze fantasy sports teams\",\n",
    "    \"develop a Python-based tool for home automation control\",\n",
    "    \"write a Python script for an automated plant watering system\",\n",
    "    \"create a Python program for a virtual reality tour guide\"\n",
    "]\n",
    "\n",
    "# Combine and shuffle all prompts\n",
    "all_prompts = core_prompts + extended_prompts + additional_prompts\n",
    "random.shuffle(all_prompts)\n",
    "\n",
    "print(f\"Total prompts available: {len(all_prompts)}\")\n",
    "print(f\"Will run: {PROMPTS_TO_RUN if PROMPTS_TO_RUN > 0 else len(all_prompts)} prompts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get OpenAI Client from SDK\n",
    "\n",
    "We'll use the SDK's OpenAI client interface to interact with the deployed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting OpenAI client for model: Qwen3-8B-GGUF\n",
      "OpenAI client configured successfully\n",
      "Endpoint: http://localhost:61100/v1\n"
     ]
    }
   ],
   "source": [
    "if deployments:\n",
    "    # Get the OpenAI client for the selected deployment\n",
    "    # Use the model name directly\n",
    "    model_name = selected_deployment.m_name\n",
    "    \n",
    "    print(f\"Getting OpenAI client for model: {model_name}\")\n",
    "    openai_client = client.openai.get_client(model_name)\n",
    "    print(f\"OpenAI client configured successfully\")\n",
    "    print(f\"Endpoint: {selected_deployment.endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Stress Test Functions\n",
    "\n",
    "These functions handle concurrent request execution and performance measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import concurrent.futures\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "def fetch_response(prompt: str, openai_client, model_name: str = \"model\") -> Tuple[str, Dict, float, Dict]:\n",
    "    \"\"\"\n",
    "    Fetch a single response from the model.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (prompt, response, duration, usage)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"You are an elite AI assistant, expert at coding. You always do everything you can to be helpful to the user\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            timeout=REQUEST_TIMEOUT\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        \n",
    "        # Extract usage statistics\n",
    "        usage = {\n",
    "            'prompt_tokens': response.usage.prompt_tokens if response.usage else 0,\n",
    "            'completion_tokens': response.usage.completion_tokens if response.usage else 0,\n",
    "            'total_tokens': response.usage.total_tokens if response.usage else 0\n",
    "        }\n",
    "        \n",
    "        # Extract the response content\n",
    "        response_dict = {\n",
    "            'content': response.choices[0].message.content,\n",
    "            'model': response.model,\n",
    "            'id': response.id\n",
    "        }\n",
    "        \n",
    "        return prompt, response_dict, duration, usage\n",
    "        \n",
    "    except Exception as e:\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        error_response = {'content': f'Error: {str(e)}', 'model': model_name, 'id': 'error'}\n",
    "        error_usage = {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}\n",
    "        return prompt, error_response, duration, error_usage\n",
    "\n",
    "\n",
    "def run_stress_test(prompts: List[str], openai_client, max_workers: int = 128) -> None:\n",
    "    \"\"\"\n",
    "    Run the stress test with multiple concurrent requests.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Starting stress test with {len(prompts)} prompts\")\n",
    "    print(f\"Max concurrent workers: {max_workers}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    total_prompt_tokens = 0\n",
    "    total_completion_tokens = 0\n",
    "    total_tokens = 0\n",
    "    successful_responses = 0\n",
    "    failed_responses = 0\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        futures = {\n",
    "            executor.submit(fetch_response, prompt, openai_client): prompt \n",
    "            for prompt in prompts\n",
    "        }\n",
    "        \n",
    "        # Process completed tasks\n",
    "        for i, future in enumerate(concurrent.futures.as_completed(futures), 1):\n",
    "            try:\n",
    "                prompt, response, duration, usage = future.result()\n",
    "                \n",
    "                # Update statistics\n",
    "                total_prompt_tokens += usage['prompt_tokens']\n",
    "                total_completion_tokens += usage['completion_tokens']\n",
    "                total_tokens += usage['total_tokens']\n",
    "                \n",
    "                if response['id'] != 'error':\n",
    "                    successful_responses += 1\n",
    "                    print(f\"[{i}/{len(prompts)}] \u2713 Completed in {duration:.2f}s\")\n",
    "                    print(f\"  Prompt: {prompt[:80]}...\")\n",
    "                    print(f\"  Tokens: {usage['total_tokens']} (prompt: {usage['prompt_tokens']}, completion: {usage['completion_tokens']})\")\n",
    "                    print(f\"  Response preview: {response['content'][:150]}...\\n\")\n",
    "                else:\n",
    "                    failed_responses += 1\n",
    "                    print(f\"[{i}/{len(prompts)}] \u2717 Failed after {duration:.2f}s\")\n",
    "                    print(f\"  Prompt: {prompt[:80]}...\")\n",
    "                    print(f\"  Error: {response['content']}\\n\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                failed_responses += 1\n",
    "                print(f\"[{i}/{len(prompts)}] \u2717 Exception: {str(e)}\\n\")\n",
    "    \n",
    "    # Calculate and display final statistics\n",
    "    total_time = time.time() - start_time\n",
    "    num_prompts = len(prompts)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"STRESS TEST RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total execution time: {total_time:.2f} seconds\")\n",
    "    print(f\"Total prompts: {num_prompts}\")\n",
    "    print(f\"Successful: {successful_responses} | Failed: {failed_responses}\")\n",
    "    \n",
    "    if successful_responses > 0:\n",
    "        avg_prompt_tokens = total_prompt_tokens / successful_responses\n",
    "        avg_completion_tokens = total_completion_tokens / successful_responses\n",
    "        avg_total_tokens = total_tokens / successful_responses\n",
    "        tokens_per_second = total_tokens / total_time if total_time > 0 else 0\n",
    "        \n",
    "        print(f\"\\nToken Statistics:\")\n",
    "        print(f\"  Total tokens: {total_tokens:,}\")\n",
    "        print(f\"  - Prompt tokens: {total_prompt_tokens:,}\")\n",
    "        print(f\"  - Completion tokens: {total_completion_tokens:,}\")\n",
    "        print(f\"\\nAverage per successful request:\")\n",
    "        print(f\"  - Prompt tokens: {avg_prompt_tokens:.1f}\")\n",
    "        print(f\"  - Completion tokens: {avg_completion_tokens:.1f}\")\n",
    "        print(f\"  - Total tokens: {avg_total_tokens:.1f}\")\n",
    "        print(f\"\\nPerformance:\")\n",
    "        print(f\"  - Overall throughput: {tokens_per_second:.1f} tokens/second\")\n",
    "        print(f\"  - Average time per request: {total_time/num_prompts:.2f} seconds\")\n",
    "    \n",
    "    print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Stress Test\n",
    "\n",
    "Execute the stress test with the configured parameters.\n",
    "\n",
    "**Note**: \n",
    "- For initial testing, start with a small number of prompts (5-10)\n",
    "- For full stress testing, use all prompts with PROMPTS_TO_RUN = -1\n",
    "- Performance will vary significantly based on:\n",
    "  - Model size and quantization\n",
    "  - Hardware (CPU vs GPU)\n",
    "  - Inference engine (vLLM, LlamaCpp, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with 5 prompts...\n",
      "Model: Qwen3-8B-GGUF\n",
      "Deployment ID: acae8693-1373-4595-bdaa-7570d2fe9c05\n",
      "Status: DEPLOYED\n",
      "Instances: 1\n",
      "\n",
      "============================================================\n",
      "Starting stress test with 5 prompts\n",
      "Max concurrent workers: 128\n",
      "============================================================\n",
      "\n",
      "[1/5] \u2713 Completed in 70.16s\n",
      "  Prompt: create a Django app for a blog where users can post, edit, and delete their blog...\n",
      "  Tokens: 2724 (prompt: 54, completion: 2670)\n",
      "  Response preview: Here's a step-by-step guide to create a Django blog app with post creation, editing, and deletion:\n",
      "\n",
      "### 1. Project Setup\n",
      "\n",
      "```bash\n",
      "django-admin startpr...\n",
      "\n",
      "[2/5] \u2713 Completed in 123.67s\n",
      "  Prompt: create a Flask API for a todo list application with CRUD operations...\n",
      "  Tokens: 2143 (prompt: 48, completion: 2095)\n",
      "  Response preview: Here's a complete Flask API for a todo list application with CRUD operations:\n",
      "\n",
      "```python\n",
      "from flask import Flask, jsonify, request, abort\n",
      "from flask_s...\n",
      "\n",
      "[3/5] \u2713 Completed in 188.76s\n",
      "  Prompt: develop a Python tool for tracking and managing personal health data...\n",
      "  Tokens: 2543 (prompt: 47, completion: 2496)\n",
      "  Response preview: Here's a comprehensive Python tool for tracking and managing personal health data. This tool includes data entry, storage, visualization, and reportin...\n",
      "\n",
      "[4/5] \u2713 Completed in 251.05s\n",
      "  Prompt: create a Python script for a basic file encryption and decryption tool...\n",
      "  Tokens: 2437 (prompt: 48, completion: 2389)\n",
      "  Response preview: Here's a basic file encryption and decryption tool using Python's `cryptography` library. This script uses Fernet symmetric encryption, which is secur...\n",
      "\n",
      "[5/5] \u2713 Completed in 293.86s\n",
      "  Prompt: write a Python program to automate the process of image tagging using AI...\n",
      "  Tokens: 1733 (prompt: 49, completion: 1684)\n",
      "  Response preview: Here's a Python program that automates image tagging using AI with TensorFlow/Keras and MobileNetV2 pre-trained model:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "i...\n",
      "\n",
      "\n",
      "============================================================\n",
      "STRESS TEST RESULTS\n",
      "============================================================\n",
      "Total execution time: 293.89 seconds\n",
      "Total prompts: 5\n",
      "Successful: 5 | Failed: 0\n",
      "\n",
      "Token Statistics:\n",
      "  Total tokens: 11,580\n",
      "  - Prompt tokens: 246\n",
      "  - Completion tokens: 11,334\n",
      "\n",
      "Average per successful request:\n",
      "  - Prompt tokens: 49.2\n",
      "  - Completion tokens: 2266.8\n",
      "  - Total tokens: 2316.0\n",
      "\n",
      "Performance:\n",
      "  - Overall throughput: 39.4 tokens/second\n",
      "  - Average time per request: 58.78 seconds\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if deployments and openai_client:\n",
    "    # Select the prompts to run\n",
    "    prompts_to_test = all_prompts[:PROMPTS_TO_RUN] if PROMPTS_TO_RUN > 0 else all_prompts\n",
    "    \n",
    "    print(f\"Testing with {len(prompts_to_test)} prompts...\")\n",
    "    print(f\"Model: {selected_deployment.m_name}\")\n",
    "    print(f\"Deployment ID: {selected_deployment.id}\")\n",
    "    print(f\"Status: {selected_deployment.status}\")\n",
    "    print(f\"Instances: {len(selected_deployment.instances)}\")\n",
    "    \n",
    "    # Run the stress test\n",
    "    run_stress_test(prompts_to_test, openai_client, max_workers=MAX_WORKERS)\n",
    "else:\n",
    "    print(\"Cannot run stress test - no active deployments or client not configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Expectations\n",
    "\n",
    "Based on typical hardware and model configurations:\n",
    "\n",
    "| Configuration | Expected Throughput | Notes |\n",
    "|--------------|-------------------|-------|\n",
    "| vLLM + RTX 4090/A100 | 500-600 tokens/s | Benefits from continuous batching |\n",
    "| LlamaCpp + M2 Max (small model) | 50-80 tokens/s | Good for local development |\n",
    "| LlamaCpp + M2 Max (large model) | 20-30 tokens/s | May timeout with many prompts |\n",
    "| CPU inference | 5-20 tokens/s | Not recommended for stress testing |\n",
    "\n",
    "**Tips for optimal performance:**\n",
    "1. Use GPU acceleration when available\n",
    "2. Choose appropriate quantization (q4_k, q5_k for balance)\n",
    "3. Adjust MAX_WORKERS based on your hardware\n",
    "4. Monitor system resources during testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Stop Deployment After Testing\n",
    "\n",
    "If you want to free up resources after testing, uncomment and run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to stop the deployment after testing\n",
    "# if deployments and model_name:\n",
    "#     print(f\"Stopping deployment for {selected_deployment.m_name}...\")\n",
    "#     result = client.serving.stop_deployment(model_name)\n",
    "#     print(f\"Deployment stopped: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}