{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85f2cc62-a32f-4bb8-8a99-e9cc0d331fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/tylerhouchin/Desktop/kamiwaza-core/kamiwaza/kamiwaza-sdk\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.25.1 in /Users/tylerhouchin/Desktop/kamiwaza-core/kamiwaza/notebook-venv/lib/python3.10/site-packages (from kamiwaza-client==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: pydantic>=1.8.1 in /Users/tylerhouchin/Desktop/kamiwaza-core/kamiwaza/notebook-venv/lib/python3.10/site-packages (from kamiwaza-client==0.1.0) (2.10.4)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/tylerhouchin/Desktop/kamiwaza-core/kamiwaza/notebook-venv/lib/python3.10/site-packages (from pydantic>=1.8.1->kamiwaza-client==0.1.0) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/tylerhouchin/Desktop/kamiwaza-core/kamiwaza/notebook-venv/lib/python3.10/site-packages (from pydantic>=1.8.1->kamiwaza-client==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/tylerhouchin/Desktop/kamiwaza-core/kamiwaza/notebook-venv/lib/python3.10/site-packages (from pydantic>=1.8.1->kamiwaza-client==0.1.0) (2.27.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tylerhouchin/Desktop/kamiwaza-core/kamiwaza/notebook-venv/lib/python3.10/site-packages (from requests>=2.25.1->kamiwaza-client==0.1.0) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tylerhouchin/Desktop/kamiwaza-core/kamiwaza/notebook-venv/lib/python3.10/site-packages (from requests>=2.25.1->kamiwaza-client==0.1.0) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tylerhouchin/Desktop/kamiwaza-core/kamiwaza/notebook-venv/lib/python3.10/site-packages (from requests>=2.25.1->kamiwaza-client==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tylerhouchin/Desktop/kamiwaza-core/kamiwaza/notebook-venv/lib/python3.10/site-packages (from requests>=2.25.1->kamiwaza-client==0.1.0) (3.10)\n",
      "Installing collected packages: kamiwaza-client\n",
      "  Attempting uninstall: kamiwaza-client\n",
      "    Found existing installation: kamiwaza-client 0.1.0\n",
      "    Uninstalling kamiwaza-client-0.1.0:\n",
      "      Successfully uninstalled kamiwaza-client-0.1.0\n",
      "  Running setup.py develop for kamiwaza-client\n",
      "Successfully installed kamiwaza-client-0.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install kamiwaza client sdk\n",
    "! cd ../../kamiwaza-sdk && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f95a77ff-15b9-4d43-b29b-f13bef59a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kamiwaza_client import KamiwazaClient\n",
    "import platform\n",
    "import re\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import openai\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Initialize the client\n",
    "client = KamiwazaClient(\"http://localhost:7777/api/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e5bd6-0af5-47a6-a55a-8f9eac885748",
   "metadata": {},
   "source": [
    "## First check if we have any models deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fad4fba-ba13-4d5e-b5f2-574b0cacff17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No models deployed\n"
     ]
    }
   ],
   "source": [
    "deployments = client.serving.list_deployments()\n",
    "if len(deployments) == 0:\n",
    "    print('No models deployed')\n",
    "else:\n",
    "    print(deployments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b43eec-d7b1-4f1a-82ef-f803a5e135ce",
   "metadata": {},
   "source": [
    "## Next, lets check if we have any models downloaded that we can deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e324b01-799c-418a-ba2d-4d7a697814e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model files downloaded\n"
     ]
    }
   ],
   "source": [
    "downloaded_models = client.models.list_model_files()\n",
    "if len(downloaded_models) == 0:\n",
    "    print('No model files downloaded')\n",
    "else:\n",
    "    print(downloaded_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f480b-99c0-4530-9dc3-0049b95807fe",
   "metadata": {},
   "source": [
    "# We do not have any models deployed or downloaded, lets get a new model, download it, and deploy it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb71a4b-7268-4f29-a1b7-dfd89d44554a",
   "metadata": {},
   "source": [
    "# 1. Let's Download a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfb45f5-d170-4af3-8d7a-7cb413ac68a6",
   "metadata": {},
   "source": [
    "### 1.1. Search for Qwen2.7-7B-Instruct on Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c488b389-a7f5-4b1d-8139-4a937e4dff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b850643-4339-4854-b962-97341e39ba22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model index: 0\n",
      "Model: Qwen2.5-7B-Instruct\n",
      "ID: None\n",
      "Repo Model ID: Qwen/Qwen2.5-7B-Instruct\n",
      "Version: None\n",
      "Author: None\n",
      "Created: None\n",
      "Files being downloaded: 0\n",
      "-----------\n",
      "model index: 1\n",
      "Model: Qwen2.5-7B-Instruct-GPTQ-Int4\n",
      "ID: None\n",
      "Repo Model ID: Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4\n",
      "Version: None\n",
      "Author: None\n",
      "Created: None\n",
      "Files being downloaded: 0\n",
      "-----------\n",
      "model index: 2\n",
      "Model: Qwen2.5-7B-Instruct-GPTQ-Int8\n",
      "ID: None\n",
      "Repo Model ID: Qwen/Qwen2.5-7B-Instruct-GPTQ-Int8\n",
      "Version: None\n",
      "Author: None\n",
      "Created: None\n",
      "Files being downloaded: 0\n",
      "-----------\n",
      "model index: 3\n",
      "Model: Qwen2.5-7B-Instruct-AWQ\n",
      "ID: None\n",
      "Repo Model ID: Qwen/Qwen2.5-7B-Instruct-AWQ\n",
      "Version: None\n",
      "Author: None\n",
      "Created: None\n",
      "Files being downloaded: 0\n",
      "-----------\n",
      "model index: 4\n",
      "Model: Qwen-Qwen2.5-7B-Instruct-llamafied\n",
      "ID: None\n",
      "Repo Model ID: llamafy/Qwen-Qwen2.5-7B-Instruct-llamafied\n",
      "Version: None\n",
      "Author: None\n",
      "Created: None\n",
      "Files being downloaded: 0\n",
      "-----------\n",
      "model index: 5\n",
      "Model: Qwen-Qwen2.5-7B-Instruct-llamafied-GGUF\n",
      "ID: None\n",
      "Repo Model ID: mradermacher/Qwen-Qwen2.5-7B-Instruct-llamafied-GGUF\n",
      "Version: None\n",
      "Author: None\n",
      "Created: None\n",
      "Files being downloaded: 0\n",
      "-----------\n",
      "model index: 6\n",
      "Model: Qwen2.5-7B-Instruct-GGUF\n",
      "ID: None\n",
      "Repo Model ID: Qwen/Qwen2.5-7B-Instruct-GGUF\n",
      "Version: None\n",
      "Author: None\n",
      "Created: None\n",
      "Files being downloaded: 0\n",
      "-----------\n",
      "model index: 7\n",
      "Model: Qwen_-_Qwen2.5-7B-Instruct-gguf\n",
      "ID: None\n",
      "Repo Model ID: RichardErkhov/Qwen_-_Qwen2.5-7B-Instruct-gguf\n",
      "Version: None\n",
      "Author: None\n",
      "Created: None\n",
      "Files being downloaded: 0\n",
      "-----------\n",
      "model index: 8\n",
      "Model: Qwen_-_Qwen2.5-7B-Instruct-4bits\n",
      "ID: None\n",
      "Repo Model ID: RichardErkhov/Qwen_-_Qwen2.5-7B-Instruct-4bits\n",
      "Version: None\n",
      "Author: None\n",
      "Created: None\n",
      "Files being downloaded: 0\n",
      "-----------\n",
      "model index: 9\n",
      "Model: Qwen_Qwen2.5-7B-Instruct\n",
      "ID: None\n",
      "Repo Model ID: croswil/Qwen_Qwen2.5-7B-Instruct\n",
      "Version: None\n",
      "Author: None\n",
      "Created: None\n",
      "Files being downloaded: 0\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "models = client.models.search_models(model_name)\n",
    "for m in range(len(models)):\n",
    "    print(f'model index: {m}')\n",
    "    print(models[m])\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cac17b2-37fa-4061-b6d6-d55c62dd892a",
   "metadata": {},
   "source": [
    "### 1.2. We have a helper function to filter these models to the ones compatible with our OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46c7b684-ab05-4d30-9c3f-afb9a8c18982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compatible models:\n",
      "Model: Qwen-Qwen2.5-7B-Instruct-llamafied-GGUF\n",
      "Repo Id: mradermacher/Qwen-Qwen2.5-7B-Instruct-llamafied-GGUF\n",
      "Compatible files:\n",
      "- Qwen-Qwen2.5-7B-Instruct-llamafied.IQ4_XS.gguf\n",
      "- Qwen-Qwen2.5-7B-Instruct-llamafied.Q2_K.gguf\n",
      "- Qwen-Qwen2.5-7B-Instruct-llamafied.Q3_K_L.gguf\n",
      "- Qwen-Qwen2.5-7B-Instruct-llamafied.Q3_K_M.gguf\n",
      "- Qwen-Qwen2.5-7B-Instruct-llamafied.Q3_K_S.gguf\n",
      "- Qwen-Qwen2.5-7B-Instruct-llamafied.Q4_0_4_4.gguf\n",
      "- Qwen-Qwen2.5-7B-Instruct-llamafied.Q4_K_M.gguf\n",
      "- Qwen-Qwen2.5-7B-Instruct-llamafied.Q4_K_S.gguf\n",
      "- Qwen-Qwen2.5-7B-Instruct-llamafied.Q5_K_M.gguf\n",
      "- Qwen-Qwen2.5-7B-Instruct-llamafied.Q5_K_S.gguf\n",
      "- Qwen-Qwen2.5-7B-Instruct-llamafied.Q6_K.gguf\n",
      "- Qwen-Qwen2.5-7B-Instruct-llamafied.Q8_0.gguf\n",
      "- Qwen-Qwen2.5-7B-Instruct-llamafied.f16.gguf\n",
      "---\n",
      "Model: Qwen2.5-7B-Instruct-GGUF\n",
      "Repo Id: Qwen/Qwen2.5-7B-Instruct-GGUF\n",
      "Compatible files:\n",
      "- qwen2.5-7b-instruct-fp16-00001-of-00004.gguf\n",
      "- qwen2.5-7b-instruct-fp16-00002-of-00004.gguf\n",
      "- qwen2.5-7b-instruct-fp16-00003-of-00004.gguf\n",
      "- qwen2.5-7b-instruct-fp16-00004-of-00004.gguf\n",
      "- qwen2.5-7b-instruct-q2_k.gguf\n",
      "- qwen2.5-7b-instruct-q3_k_m.gguf\n",
      "- qwen2.5-7b-instruct-q4_0-00001-of-00002.gguf\n",
      "- qwen2.5-7b-instruct-q4_0-00002-of-00002.gguf\n",
      "- qwen2.5-7b-instruct-q4_k_m-00001-of-00002.gguf\n",
      "- qwen2.5-7b-instruct-q4_k_m-00002-of-00002.gguf\n",
      "- qwen2.5-7b-instruct-q5_0-00001-of-00002.gguf\n",
      "- qwen2.5-7b-instruct-q5_0-00002-of-00002.gguf\n",
      "- qwen2.5-7b-instruct-q5_k_m-00001-of-00002.gguf\n",
      "- qwen2.5-7b-instruct-q5_k_m-00002-of-00002.gguf\n",
      "- qwen2.5-7b-instruct-q6_k-00001-of-00002.gguf\n",
      "- qwen2.5-7b-instruct-q6_k-00002-of-00002.gguf\n",
      "- qwen2.5-7b-instruct-q8_0-00001-of-00003.gguf\n",
      "- qwen2.5-7b-instruct-q8_0-00002-of-00003.gguf\n",
      "- qwen2.5-7b-instruct-q8_0-00003-of-00003.gguf\n",
      "---\n",
      "Model: Qwen_-_Qwen2.5-7B-Instruct-gguf\n",
      "Repo Id: RichardErkhov/Qwen_-_Qwen2.5-7B-Instruct-gguf\n",
      "Compatible files:\n",
      "- Qwen2.5-7B-Instruct.IQ3_M.gguf\n",
      "- Qwen2.5-7B-Instruct.IQ3_S.gguf\n",
      "- Qwen2.5-7B-Instruct.IQ3_XS.gguf\n",
      "- Qwen2.5-7B-Instruct.IQ4_NL.gguf\n",
      "- Qwen2.5-7B-Instruct.IQ4_XS.gguf\n",
      "- Qwen2.5-7B-Instruct.Q2_K.gguf\n",
      "- Qwen2.5-7B-Instruct.Q3_K.gguf\n",
      "- Qwen2.5-7B-Instruct.Q3_K_L.gguf\n",
      "- Qwen2.5-7B-Instruct.Q3_K_M.gguf\n",
      "- Qwen2.5-7B-Instruct.Q3_K_S.gguf\n",
      "- Qwen2.5-7B-Instruct.Q4_0.gguf\n",
      "- Qwen2.5-7B-Instruct.Q4_1.gguf\n",
      "- Qwen2.5-7B-Instruct.Q4_K.gguf\n",
      "- Qwen2.5-7B-Instruct.Q4_K_M.gguf\n",
      "- Qwen2.5-7B-Instruct.Q4_K_S.gguf\n",
      "- Qwen2.5-7B-Instruct.Q5_0.gguf\n",
      "- Qwen2.5-7B-Instruct.Q5_1.gguf\n",
      "- Qwen2.5-7B-Instruct.Q5_K.gguf\n",
      "- Qwen2.5-7B-Instruct.Q5_K_M.gguf\n",
      "- Qwen2.5-7B-Instruct.Q5_K_S.gguf\n",
      "- Qwen2.5-7B-Instruct.Q6_K.gguf\n",
      "- Qwen2.5-7B-Instruct.Q8_0.gguf\n",
      "---\n",
      "Model: Qwen_Qwen2.5-7B-Instruct\n",
      "Repo Id: croswil/Qwen_Qwen2.5-7B-Instruct\n",
      "Compatible files:\n",
      "- Qwen2.5-7B-Instruct-Q4_K_M.gguf\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "compatible_models = client.models.filter_compatible_models(\"Qwen/Qwen2.5-7B-Instruct\")\n",
    "\n",
    "print(\"Compatible models:\")\n",
    "for model_info in compatible_models:\n",
    "    print(f\"Model: {model_info['model'].name}\")\n",
    "    print(f\"Repo Id: {model_info['model'].repo_modelId}\")\n",
    "    print(\"Compatible files:\")\n",
    "    for file in model_info['files']:\n",
    "        print(f\"- {file.name}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08935889-8258-485a-88f9-aa1bcc4c3380",
   "metadata": {},
   "source": [
    "### 1.3. Using the helper function, we select a repo that we want to download the model from and a desired quantization. We initate the download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50901d72-c40f-441f-8e25-f1c45ead994d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model: Qwen2.5-7B-Instruct-GGUF\n",
      "Files being downloaded:\n",
      "- qwen2.5-7b-instruct-q6_k-00001-of-00002.gguf\n",
      "- qwen2.5-7b-instruct-q6_k-00002-of-00002.gguf\n"
     ]
    }
   ],
   "source": [
    "# Initiate the download\n",
    "repo_id = \"Qwen/Qwen2.5-7B-Instruct-GGUF\"\n",
    "download_info = client.models.initiate_model_download(repo_id, quantization='q6_k')\n",
    "\n",
    "print(f\"Downloading model: {download_info['model'].name}\")\n",
    "print(\"Files being downloaded:\")\n",
    "for file in download_info['files']:\n",
    "    print(f\"- {file.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343fc02a-7a1d-4d3a-b54b-7157a19a6fd1",
   "metadata": {},
   "source": [
    "### 1.4. We can monitor the status of the download here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eceb4f86-45bf-460d-a411-5d19a5f86d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download Status for Qwen/Qwen2.5-7B-Instruct-GGUF:\n",
      "-----------------------------\n",
      "Model ID: 847e2da0-816c-4c37-a923-5f655faa54fa\n",
      "Model File ID: 80ff9260-9f21-46ae-b1e4-6f2839b47b39\n",
      "Model Name: qwen2.5-7b-instruct-q6_k-00001-of-00002.gguf\n",
      "Download Progress: 100%\n",
      "-----------------------------\n",
      "All downloads completed!\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"Qwen/Qwen2.5-7B-Instruct-GGUF\"\n",
    "\n",
    "def all_downloads_complete(status):\n",
    "    return all(s.download_percentage == 100 for s in status)\n",
    "\n",
    "while True:\n",
    "    status = client.models.check_download_status(repo_id)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(f\"Download Status for {repo_id}:\")\n",
    "    print(\"-----------------------------\")\n",
    "    \n",
    "    for s in status:\n",
    "        print(f\"Model ID: {s.m_id}\")\n",
    "        print(f\"Model File ID: {s.id}\")\n",
    "        print(f\"Model Name: {s.name}\")\n",
    "        print(f\"Download Progress: {s.download_percentage}%\")\n",
    "        print(\"-----------------------------\")\n",
    "    \n",
    "    if all_downloads_complete(status):\n",
    "        print(\"All downloads completed!\")\n",
    "        break\n",
    "    \n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba6139d-76ca-4e9d-b02a-cf89ec243147",
   "metadata": {},
   "source": [
    "# 2. Now let's deploy this model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1cec4c-70bc-44dd-9781-54459d422c5d",
   "metadata": {},
   "source": [
    "### 2.1. Get the default model config file (optional)\n",
    "This was created when we downloaded the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6155fea-1a0e-4059-8a1d-356577df821f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelConfig: Default Model Config\n",
       "ID: 2546ef96-9135-4ca7-ad8f-0f74f8cd7853\n",
       "Model ID: 847e2da0-816c-4c37-a923-5f655faa54fa\n",
       "Default: True\n",
       "Created: 2024-12-27 23:53:37.224340\n",
       "Kamiwaza Version: None"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the model id from the status \n",
    "model_id = '847e2da0-816c-4c37-a923-5f655faa54fa'\n",
    "configs = client.models.get_model_configs(model_id)\n",
    "default_config = next((config for config in configs if config.default), configs[0])\n",
    "default_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d806e-d084-40ff-aa73-2ea3e49d9169",
   "metadata": {},
   "source": [
    "### 2.2 Deploy the model with default params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12fd0aa9-3261-4990-85f2-acced0aea997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UIModelDeployment: ID: 92c54dc7-87ec-4427-8453-3df7b104f3b4\n",
      "Model Name: Qwen2.5-7B-Instruct-GGUF\n",
      "Status: DEPLOYED\n",
      "Instances: 1\n",
      "Host IP: None]\n"
     ]
    }
   ],
   "source": [
    "deployment_id = client.serving.deploy_model(model_id)\n",
    "deployments = client.serving.list_deployments()\n",
    "print(deployments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebbfd28-d9e5-4099-9a93-5d9996811f90",
   "metadata": {},
   "source": [
    "# 3. Let's do some inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73a6fbe6-6f09-401f-817d-16980c79cc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a deployment of Qwen2.5-7B-Instruct-GGUF - using it\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "deployments = client.serving.list_deployments()\n",
    "valid_deployment = None\n",
    "for deployment in deployments:\n",
    "    if deployment.status == 'DEPLOYED' and deployment.instances:\n",
    "        valid_deployment = deployment\n",
    "        print(f\"Found a deployment of {deployment.m_name} - using it\")\n",
    "        break\n",
    "if valid_deployment is None:\n",
    "    print(\"No valid deployments found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "05afe098-5368-46f7-a30f-599f15b890fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51100"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_deployment.lb_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "978c6cae-35d7-4b3c-b80e-aaaff67c291d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: http://localhost:51100/v1/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 16:02:28,624 - httpx - INFO - HTTP Request: POST http://localhost:51100/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model response:\n",
      "The capital of New Jersey is Trenton.\n",
      "\n",
      "The capital of California is Sacramento.\n",
      "\n",
      "In Mandarin, 'green tea' is said as '绿茶' (lǜ guā lì).\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "from openai import OpenAI\n",
    "\n",
    "http_client = httpx.Client(base_url=f\"http://localhost:{valid_deployment.lb_port}/v1\")\n",
    "\n",
    "# Initialize the OpenAI client with the custom http_client\n",
    "openai_client = OpenAI(\n",
    "    api_key=\"local\",\n",
    "    base_url=f\"http://localhost:{valid_deployment.lb_port}/v1\",\n",
    "    http_client=http_client\n",
    ")\n",
    "\n",
    "print(f\"Endpoint: {openai_client.base_url}\")\n",
    "\n",
    "# Perform inference\n",
    "try:\n",
    "    chat_completion = openai_client.chat.completions.create(\n",
    "        model=\"local-model\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"What is the capital of New Jersey? What about California? And how do I say 'green tea' in mandarin?\"}\n",
    "        ]\n",
    "    )\n",
    "    print(\"Model response:\")\n",
    "    print(chat_completion.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during inference: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
