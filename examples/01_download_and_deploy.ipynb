{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c32fc3a-bb41-468b-a3b4-6d4629d17657",
   "metadata": {},
   "source": [
    "# Model Download and Deployment with Kamiwaza SDK\n",
    "\n",
    "This notebook demonstrates how to download and deploy models using the Kamiwaza SDK. We'll walk through the complete process step-by-step:\n",
    "\n",
    "1. Searching for models\n",
    "2. Downloading model files\n",
    "3. Deploying the model\n",
    "4. Using the model with the OpenAI compatible interface\n",
    "5. Stopping the model deployment\n",
    "\n",
    "In this example, we're using a small language model ([Qwen/Qwen2.5-Coder-0.5B-Instruct-GGUF](https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B-Instruct-GGUF)), but the same process works for any supported model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39734d24-c68b-4b39-99c6-e7e2eae74fbe",
   "metadata": {},
   "source": [
    "## Initialize the Kamiwaza Client\n",
    "\n",
    "First, we initialize the client by connecting to our Kamiwaza server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b1ba97-29fa-44c1-b8cd-1a547ad17dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kamiwaza_client import KamiwazaClient\n",
    "\n",
    "# Initialize the client\n",
    "client = KamiwazaClient(\"http://localhost:7777/api/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ac8454-bde3-417f-a5f5-37b315470362",
   "metadata": {},
   "source": [
    "## Search for a Model\n",
    "\n",
    "Let's search for a specific model from Hugging Face. We use the `search_models` method with the repository ID and set `exact=True` to find an exact match.\n",
    "\n",
    "The search results show:\n",
    "- Model name and repository ID\n",
    "- Available files and their types\n",
    "- Available quantization levels (fp16, q2_k, q3_k, etc.)\n",
    "- Download status information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b68f67-d90c-45e9-98b0-62586cea8c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model: Qwen2.5-Coder-0.5B-Instruct-GGUF\n",
       " Repo ID: Qwen/Qwen2.5-Coder-0.5B-Instruct-GGUF\n",
       " Files: 12 available\n",
       "   GITATTRIBUTES files: 1\n",
       "   UNKNOWN files: 1\n",
       "   MD files: 1\n",
       "   GGUF files: 9\n",
       " Available quantizations:\n",
       "   - fp16\n",
       "   - q2_k\n",
       "   - q3_k\n",
       "   - q4_0\n",
       "   - q4_k\n",
       "   - q5_0\n",
       "   - q5_k\n",
       "   - q6_k\n",
       "   - q8_0\n",
       " Files: 0 downloading]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_repo = 'Qwen/Qwen2.5-Coder-0.5B-Instruct-GGUF'\n",
    "client.models.search_models(hf_repo, exact = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054e0a2b-9619-4da8-8c16-feb4233735d4",
   "metadata": {},
   "source": [
    "## Download the Model Files\n",
    "\n",
    "Now we'll initiate the model download using `initiate_model_download`. \n",
    "\n",
    "By default, this downloads the best quantization for your hardware. You can specify a particular quantization level by adding a parameter like:\n",
    "\n",
    "```python\n",
    "client.models.initiate_model_download(hf_repo, quantization=\"q4_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe9ec9a-9548-4984-bb96-ffbc43ba5fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': Model: Qwen2.5-Coder-0.5B-Instruct-GGUF\n",
       " Repo ID: Qwen/Qwen2.5-Coder-0.5B-Instruct-GGUF\n",
       " Files: 1 available\n",
       "   GGUF files: 1\n",
       " Available quantizations:\n",
       "   - fp16\n",
       "   - q2_k\n",
       "   - q3_k\n",
       "   - q4_0\n",
       "   - q4_k\n",
       "   - q5_0\n",
       "   - q5_k\n",
       "   - q6_k\n",
       "   - q8_0\n",
       " Files: 0 downloading,\n",
       " 'files': [ModelFile: qwen2.5-coder-0.5b-instruct-q6_k.gguf\n",
       "  Size: 620.25 MB],\n",
       " 'download_request': ModelDownloadRequest: Model: Qwen/Qwen2.5-Coder-0.5B-Instruct-GGUF, Version: None, Hub: HubsHf,\n",
       " 'result': {'result': True,\n",
       "  'message': 'Downloads queued',\n",
       "  'files': ['9b75e90e-1a86-49d7-9953-32242156fbe8']}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.initiate_model_download(hf_repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08a72ca-0008-4762-b2ec-e0e60eaaa54d",
   "metadata": {},
   "source": [
    "## Check Download Status\n",
    "\n",
    "After initiating the download, we can check its status to see the progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e842b070-889f-4d9c-afe1-1a4a4343de96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelDownloadStatus: qwen2.5-coder-0.5b-instruct-q6_k.gguf\n",
       " ID: 9b75e90e-1a86-49d7-9953-32242156fbe8\n",
       " Model ID: d67d5808-f95b-466f-9f85-09e1354553d7\n",
       " Is Downloading: True\n",
       " Download Progress: 0%]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.check_download_status(hf_repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be211c-25d1-4daf-9258-935eb2fef9ac",
   "metadata": {},
   "source": [
    "## Wait for Download Completion\n",
    "\n",
    "Instead of repeatedly checking the status, we can use the `wait_for_download` method to wait until all downloads are complete. This method provides progress updates and a summary once the download finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d373c65d-1b08-43fe-a09f-ae4b72ebac85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall: 95.0% [02:36] | Active: 1, Completed: 0, Total: 1 | qwen2.5-coder-0.5b-instruct-q6_k.gguf: 95% (6.16MB/s)\n",
      "Download complete for: Qwen/Qwen2.5-Coder-0.5B-Instruct-GGUF\n",
      "Total download time: 02:41\n",
      "Files downloaded:\n",
      "- qwen2.5-coder-0.5b-instruct-q6_k.gguf (620.25 MB)\n",
      "Model ID: d67d5808-f95b-466f-9f85-09e1354553d7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ModelDownloadStatus: qwen2.5-coder-0.5b-instruct-q6_k.gguf\n",
       " ID: 9b75e90e-1a86-49d7-9953-32242156fbe8\n",
       " Model ID: d67d5808-f95b-466f-9f85-09e1354553d7\n",
       " Is Downloading: True\n",
       " Download Progress: 95% (6.16MB/s), 00:05 remaining\n",
       " Download time: 01:36]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.wait_for_download(hf_repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597abe60-b509-4481-90de-6f2e509dff79",
   "metadata": {},
   "source": [
    "## Deploy the Model\n",
    "\n",
    "Once the model is downloaded, we can deploy it using `deploy_model`. This method prepares the model for inference and returns a deployment ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e75794ee-9939-47f8-ad99-66a61ea9d002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('81ed8fce-4237-40d2-af76-feef5698bee2')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.serving.deploy_model(repo_id=hf_repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09be96d3-3241-4066-a151-1e80accbcd0d",
   "metadata": {},
   "source": [
    "## List Active Deployments\n",
    "\n",
    "We can view all active model deployments to confirm our model is running. The output shows:\n",
    "- Deployment ID and model ID\n",
    "- Model name\n",
    "- Status (DEPLOYED, STARTING, etc.)\n",
    "- Instance information\n",
    "- The endpoint URL for making inference requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cca50802-e0b5-4f9c-a060-a5e3fbd6aeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ActiveModelDeployment(id=UUID('81ed8fce-4237-40d2-af76-feef5698bee2'), m_id=UUID('d67d5808-f95b-466f-9f85-09e1354553d7'), m_name='Qwen2.5-Coder-0.5B-Instruct-GGUF', status='DEPLOYED', instances=[ModelInstance:\n",
       " ID: 49ba59dc-6021-41ab-943b-1d0871cab23c\n",
       " Deployment ID: 81ed8fce-4237-40d2-af76-feef5698bee2\n",
       " Status: DEPLOYED\n",
       " Listen Port: 50555], lb_port=51122, endpoint='http://localhost:51122/v1'),\n",
       " ActiveModelDeployment(id=UUID('2fd2e948-8441-4e88-9179-bc7321600b62'), m_id=UUID('39164ffe-4ba8-4e6e-9b90-42a4e38e4900'), m_name='Qwen2.5-7B-Instruct-GGUF', status='DEPLOYED', instances=[ModelInstance:\n",
       " ID: 8102cc7b-bcb8-4bd6-a546-b40610335bf9\n",
       " Deployment ID: 2fd2e948-8441-4e88-9179-bc7321600b62\n",
       " Status: DEPLOYED\n",
       " Listen Port: 49515], lb_port=51121, endpoint='http://localhost:51121/v1')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.serving.list_active_deployments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e51aa47-7ee2-46d0-8784-c37c3052f02e",
   "metadata": {},
   "source": [
    "## Use the OpenAI Compatible Interface\n",
    "\n",
    "Kamiwaza provides an OpenAI-compatible interface, making it easy to use familiar tools with your deployed models. We create an OpenAI client using the `get_client` method.\n",
    "\n",
    "Now we can use the standard OpenAI API patterns to interact with our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24224749-89cc-4597-8e9c-19cb60a019e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = client.openai.get_client(repo_id=hf_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "735aaed0-0cc1-4b68-80e6-d797d0f37d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 13:46:47,056 - httpx - INFO - HTTP Request: POST http://localhost:51122/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1"
     ]
    }
   ],
   "source": [
    "# Create a streaming chat completion\n",
    "response = openai_client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"How many r's are in the word 'strawberry'? ONLY RESPOND WITH A SINGLE NUMBER\"}\n",
    "    ],\n",
    "    model=\"model\",\n",
    "    stream=True \n",
    ")\n",
    "\n",
    "# display the stream\n",
    "for chunk in response:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ecfb25-8217-492c-a889-f4fc74370e95",
   "metadata": {},
   "source": [
    "## Stop the Model Deployment\n",
    "\n",
    "When we're done using the model, we can stop the deployment to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5aa10dcd-f3a9-4d11-aae9-499ef693d676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.serving.stop_deployment(repo_id=hf_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06e53463-b242-47e0-b762-a7b4d1a20ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.serving.list_active_deployments()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
